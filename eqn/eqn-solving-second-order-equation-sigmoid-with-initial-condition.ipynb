{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Differential Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "num_neurons = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Data\n",
    "# train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "#                          7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_X = np.asarray(range(10))\n",
    "num_points  = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] 10\n"
     ]
    }
   ],
   "source": [
    "print(train_X, num_points )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24997802, -1.08358988,  0.3742617 ,  0.15604158, -1.05727945,\n",
       "        0.89324029, -0.33721135, -0.47155053, -0.15089272,  0.68079832])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\", shape=(num_points))\n",
    "S = tf.placeholder(\"float\", shape=([num_neurons,num_points]) )\n",
    "S1_S = tf.placeholder(\"float\", shape=([num_neurons,num_points]) )\n",
    "VW = tf.placeholder(\"float\", shape=([num_neurons,num_points]) )\n",
    "Y = tf.placeholder(\"float\", shape=(num_points))\n",
    "dYdX = tf.placeholder(\"float\", shape=(num_points))\n",
    "\n",
    "# Set model weights\n",
    "# W = tf.Variable(rng.randn(num_neurons), name=\"weight\", dtype=tf.float32)\n",
    "# U = tf.Variable(rng.randn(num_neurons), name=\"bias\", dtype=tf.float32)\n",
    "# V = tf.Variable(rng.randn(num_neurons), name=\"scale\", dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable(np.arange(num_neurons), name=\"weight\", dtype=tf.float32)\n",
    "U = tf.Variable(np.arange(num_neurons), name=\"bias\", dtype=tf.float32)\n",
    "V = tf.Variable(np.arange(num_neurons), name=\"scale\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some convinient variables/placeholders, to simplify the cost expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = tf.reshape( tf.multiply( tf.reshape(W , [1,num_neurons]),  tf.reshape(X, [num_points,1]) ), [num_points*num_neurons] )\n",
    "S = tf.nn.sigmoid( tf.multiply( tf.reshape(W , [1,num_neurons]),  tf.reshape(X, [num_points,1]) ) )  \n",
    "S1_S = tf.multiply(S , (1-S)) \n",
    "VW = tf.multiply(V,W)\n",
    "VW_cast = tf.reshape( tf.tile( VW , [num_points] ) , [num_points, num_neurons] )\n",
    "V_cast =  tf.reshape( tf.tile( V , [num_points] ) , [num_points, num_neurons] )\n",
    "Y = 1 + tf.multiply( X, tf.matmul( S, tf.transpose( V_cast ) )[:,0] )\n",
    "dYdX =  tf.multiply(X , tf.matmul( S1_S, tf.transpose(VW_cast) ) [:,0] ) + tf.matmul( S, tf.transpose( V_cast ) )[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parametrize unknow function y\n",
    "\n",
    "$$\n",
    "y_j = 1 + \\sum_i V_i S(W_i X_j + U_i)\n",
    "$$\n",
    "\n",
    "I can also calculate $dy/dx$\n",
    "\n",
    "$$\n",
    "(dy/dx)_i =  \\sum_i X_j V_i W_i S(W_i X_j + U_i) ( 1- S(W_i X_j + U_i) ) + \\sum_i V_i S(W_i X_j + U_i)\n",
    "$$\n",
    "\n",
    "The result I want to get is $dy/dx + y$, which becomes\n",
    "\n",
    "$$\n",
    "(dy/dx + y)_i = \\sum_i V_i W_i S(W_i X_j + U_i) ( 1- S(W_i X_j + U_i) )  + 1+  \\sum_i V_i S(W_i X_j + U_i)\n",
    "$$\n",
    "\n",
    "To achieve this, I have to understand the broadcasting in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S =  [[ 0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "   0.5         0.5         0.5       ]\n",
      " [ 0.5         0.7310586   0.88079703  0.95257413  0.98201376  0.99330717\n",
      "   0.99752742  0.999089    0.99966466  0.99987662]\n",
      " [ 0.5         0.88079703  0.98201376  0.99752742  0.99966466  0.99995458\n",
      "   0.9999938   0.99999917  0.99999988  1.        ]\n",
      " [ 0.5         0.95257413  0.99752742  0.99987662  0.9999938   0.99999964\n",
      "   1.          1.          1.          1.        ]\n",
      " [ 0.5         0.98201376  0.99966466  0.9999938   0.99999988  1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.5         0.99330717  0.99995458  0.99999964  1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.5         0.99752742  0.9999938   1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.5         0.999089    0.99999917  1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.5         0.99966466  0.99999988  1.          1.          1.          1.\n",
      "   1.          1.          1.        ]\n",
      " [ 0.5         0.99987662  1.          1.          1.          1.          1.\n",
      "   1.          1.          1.        ]] \n",
      "\n",
      "\n",
      "S1_S =  [[  2.50000000e-01   2.50000000e-01   2.50000000e-01   2.50000000e-01\n",
      "    2.50000000e-01   2.50000000e-01   2.50000000e-01   2.50000000e-01\n",
      "    2.50000000e-01   2.50000000e-01]\n",
      " [  2.50000000e-01   1.96611926e-01   1.04993626e-01   4.51766551e-02\n",
      "    1.76627338e-02   6.64803293e-03   2.46646581e-03   9.10167466e-04\n",
      "    3.35223274e-04   1.23366393e-04]\n",
      " [  2.50000000e-01   1.04993626e-01   1.76627338e-02   2.46646581e-03\n",
      "    3.35223274e-04   4.54166766e-05   6.19884486e-06   8.34464345e-07\n",
      "    1.19209275e-07   0.00000000e+00]\n",
      " [  2.50000000e-01   4.51766551e-02   2.46646581e-03   1.23366393e-04\n",
      "    6.19884486e-06   3.57627755e-07   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   1.76627338e-02   3.35223274e-04   6.19884486e-06\n",
      "    1.19209275e-07   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   6.64803293e-03   4.54166766e-05   3.57627755e-07\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   2.46646581e-03   6.19884486e-06   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   9.10167466e-04   8.34464345e-07   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   3.35223274e-04   1.19209275e-07   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.50000000e-01   1.23366393e-04   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]] \n",
      "\n",
      "\n",
      "VW =  [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.] \n",
      "\n",
      "\n",
      "VW_cast =  [[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      " [  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]] \n",
      "\n",
      "\n",
      "V_cast =  [[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]] \n",
      "\n",
      "\n",
      "S1_S. VW_cast =  [[  7.12500000e+01   7.12500000e+01   7.12500000e+01   7.12500000e+01\n",
      "    7.12500000e+01   7.12500000e+01   7.12500000e+01   7.12500000e+01\n",
      "    7.12500000e+01   7.12500000e+01]\n",
      " [  1.63681889e+00   1.63681889e+00   1.63681889e+00   1.63681889e+00\n",
      "    1.63681889e+00   1.63681889e+00   1.63681889e+00   1.63681889e+00\n",
      "    1.63681889e+00   1.63681889e+00]\n",
      " [  2.04613417e-01   2.04613417e-01   2.04613417e-01   2.04613417e-01\n",
      "    2.04613417e-01   2.04613417e-01   2.04613417e-01   2.04613417e-01\n",
      "    2.04613417e-01   2.04613417e-01]\n",
      " [  5.62609397e-02   5.62609397e-02   5.62609397e-02   5.62609397e-02\n",
      "    5.62609397e-02   5.62609397e-02   5.62609397e-02   5.62609397e-02\n",
      "    5.62609397e-02   5.62609397e-02]\n",
      " [  1.90613233e-02   1.90613233e-02   1.90613233e-02   1.90613233e-02\n",
      "    1.90613233e-02   1.90613233e-02   1.90613233e-02   1.90613233e-02\n",
      "    1.90613233e-02   1.90613233e-02]\n",
      " [  6.83291815e-03   6.83291815e-03   6.83291815e-03   6.83291815e-03\n",
      "    6.83291815e-03   6.83291815e-03   6.83291815e-03   6.83291815e-03\n",
      "    6.83291815e-03   6.83291815e-03]\n",
      " [  2.49126111e-03   2.49126111e-03   2.49126111e-03   2.49126111e-03\n",
      "    2.49126111e-03   2.49126111e-03   2.49126111e-03   2.49126111e-03\n",
      "    2.49126111e-03   2.49126111e-03]\n",
      " [  9.13505326e-04   9.13505326e-04   9.13505326e-04   9.13505326e-04\n",
      "    9.13505326e-04   9.13505326e-04   9.13505326e-04   9.13505326e-04\n",
      "    9.13505326e-04   9.13505326e-04]\n",
      " [  3.35700111e-04   3.35700111e-04   3.35700111e-04   3.35700111e-04\n",
      "    3.35700111e-04   3.35700111e-04   3.35700111e-04   3.35700111e-04\n",
      "    3.35700111e-04   3.35700111e-04]\n",
      " [  1.23366393e-04   1.23366393e-04   1.23366393e-04   1.23366393e-04\n",
      "    1.23366393e-04   1.23366393e-04   1.23366393e-04   1.23366393e-04\n",
      "    1.23366393e-04   1.23366393e-04]] \n",
      "\n",
      "\n",
      "sliced  [  7.12500000e+01   1.63681889e+00   2.04613417e-01   5.62609397e-02\n",
      "   1.90613233e-02   6.83291815e-03   2.49126111e-03   9.13505326e-04\n",
      "   3.35700111e-04   1.23366393e-04] \n",
      "\n",
      "\n",
      "dYdX =  [ 22.5         45.85678101  45.24501801  45.11601257  45.0575676\n",
      "  45.0273819   45.0124588   45.00548172  45.00234985  45.00098801] \n",
      "\n",
      "\n",
      "Y =  [   1.           45.21996307   90.67158508  135.84169006  180.92529297\n",
      "  225.96609497  270.9850769   315.99362183  360.99731445  405.99890137]\n"
     ]
    }
   ],
   "source": [
    "init_test = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess_test:\n",
    "    \n",
    "    sess_test.run(init_test)\n",
    "    \n",
    "    print( \"S = \", sess_test.run(S, feed_dict={X:train_X} ) , '\\n\\n')\n",
    "    print( \"S1_S = \", sess_test.run( S1_S  , feed_dict={X:train_X} ) ,'\\n\\n')\n",
    "    print( \"VW = \", sess_test.run( VW  , feed_dict={X:train_X} ) ,'\\n\\n')\n",
    "    print( \"VW_cast = \", sess_test.run( VW_cast  , feed_dict={X:train_X} ) ,'\\n\\n')\n",
    "    print(\"V_cast = \", sess_test.run( V_cast  , feed_dict={X:train_X} ) ,'\\n\\n')\n",
    "    print( \"S1_S. VW_cast = \", sess_test.run( tf.matmul( S1_S, tf.transpose(VW_cast) )  , feed_dict={X:train_X} ) , '\\n\\n')\n",
    "    print( \"sliced \", sess_test.run(  tf.matmul( S1_S, tf.transpose(VW_cast) ) [:,0]   , feed_dict={X:train_X} ) , '\\n\\n') # Access the first column of the tensorl\n",
    "    print( \"dYdX = \",  sess_test.run( dYdX, feed_dict={X:train_X}  ) , '\\n\\n')\n",
    "    print( \"Y = \",  sess_test.run( Y, feed_dict={X:train_X}  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a linear model\n",
    "# pred = tf.add(tf.multiply(tf.square(X), W), b)\n",
    "# pred = tf.multiply(  tf.nn.sigmoid( tf.add(tf.multiply( X, W), b) ) , v )\n",
    "\n",
    "pred =  dYdX + Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred , 2))/( 2 * num_points )\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Finished!\n",
      "Training cost =  254535.0 \n",
      " W= [ 0.          0.75768089  1.97467053  3.00136638  4.00706339  5.00623226\n",
      "  6.00408459  7.00232935  8.00122261  9.00060654] \n",
      " U= [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.] \n",
      " V= [ -8.67854023 -16.27683258 -15.34618759 -14.3501606  -13.34872627\n",
      " -12.34718132 -11.34623528 -10.34574699  -9.3455143   -8.34540939] \n",
      "\n",
      "\n",
      "[  1.00000000e+00  -1.06284241e+02  -2.23257080e+02  -3.40485657e+02\n",
      "  -4.57543274e+02  -5.74151306e+02  -6.90321777e+02  -8.06174988e+02\n",
      "  -9.21827271e+02  -1.03736157e+03]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102781550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    sess.run(optimizer, feed_dict = {X: train_X})\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X})\n",
    "    print(\"Training cost = \", training_cost, \"\\n W=\", sess.run(W), \"\\n U=\", sess.run(U),\"\\n V=\", sess.run(V), '\\n\\n')\n",
    "    \n",
    "    print( sess.run(Y, feed_dict={X:train_X}) )\n",
    "    \n",
    "    plt.plot(train_X, np.exp(-train_X), 'r-', label = 'True Solution' )\n",
    "    \n",
    "    plt.plot(train_X, sess.run(Y, feed_dict={X:train_X}), 'b+', label='Network Simulated Data')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
